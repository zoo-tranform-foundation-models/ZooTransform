{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T15:46:53.462441Z",
     "start_time": "2025-11-05T15:46:53.284627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\t     ZooTransform  docker-examples\t     models.md\r\n",
      "Makefile\t     config.mk\t   entrypoint.sh\t     pyproject.toml\r\n",
      "ProteinGym_DMS_data  configure\t   jupyter_server_config.py  tutorials\r\n",
      "README.md\t     data\t   license.txt\t\t     uv.lock\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "Using device: cuda\n",
      "  GPU: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 42.29 GB\n",
      "Loading model: facebook/esm2_t6_8M_UR50D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding species tokens: ['<sp_human>', '<sp_mouse>', '<sp_ecoli>']\n",
      "Added 3 new special tokens\n",
      "Resized model embeddings to 36 tokens\n",
      "✓ Model and tokenizer ready!\n",
      "  Hidden size: 320\n",
      "  Number of layers: 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_root = os.path.join(os.getcwd(), \"ZooTransform\") # TODO - Adjust this path as necessary\n",
    "os.chdir(data_root)\n",
    "\n",
    "from src.fine_tuning.fine_tuning import LoraFinetuner\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from src.model.species_model import SpeciesAwareESM2\n",
    "species_model = SpeciesAwareESM2(species_list=[\"human\",\"mouse\",\"ecoli\"]) #TODO - Replace with actual species"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T15:47:02.917668Z",
     "start_time": "2025-11-05T15:46:55.347267Z"
    }
   },
   "id": "9aaa9a30206b8f3a",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2406bdf8a7b963e0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data for embedding - need to replace with our actual data\n",
    "data = pd.DataFrame({\n",
    "    \"species\": [\"human\", \"mouse\", \"ecoli\", \"human\", \"mouse\", \"ecoli\",\"human\", \"mouse\", \"ecoli\",\"human\", \"mouse\", \"ecoli\"],\n",
    "    \"sequence\": [\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "species_batch = data[\"species\"]\n",
    "sequence_batch = data[\"sequence\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T15:47:08.460054Z",
     "start_time": "2025-11-05T15:47:08.456254Z"
    }
   },
   "id": "f631a1b680ed38c6",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define objective function for LoRA hyperparameter tuning (without masked embeddings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc1f23b9bc51e9c7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-05 13:03:55,675] A new study created in memory with name: no-name-3f0bb664-894d-4e5e-9716-42492ed0e0e9\n",
      "/tmp/ipykernel_41431/371779959.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "Epoch 1/5: 100%|██████████| 6/6 [00:00<00:00, 14.98it/s, loss=0.1089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 6/6 [00:00<00:00, 47.77it/s, loss=0.1059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 6/6 [00:00<00:00, 48.47it/s, loss=0.1018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 0.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 6/6 [00:00<00:00, 48.45it/s, loss=0.0984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — avg loss: 0.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 6/6 [00:00<00:00, 47.55it/s, loss=0.0958]\n",
      "[I 2025-11-05 13:03:57,093] Trial 0 finished with value: 0.10374657834569614 and parameters: {'r': 25, 'alpha': 62.26954583607888, 'lr': 4.636950770235651e-05, 'batch_size': 2}. Best is trial 0 with value: 0.10374657834569614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — avg loss: 0.0968\n",
      "Returning final average loss across epochs: 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 6/6 [00:00<00:00, 48.45it/s, loss=0.1109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 6/6 [00:00<00:00, 47.55it/s, loss=0.1096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 0.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 6/6 [00:00<00:00, 47.57it/s, loss=0.1089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 6/6 [00:00<00:00, 48.58it/s, loss=0.1069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — avg loss: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 6/6 [00:00<00:00, 48.76it/s, loss=0.1070]\n",
      "[I 2025-11-05 13:03:57,739] Trial 1 finished with value: 0.10928999433914821 and parameters: {'r': 29, 'alpha': 62.20296079792073, 'lr': 1.681000246194575e-05, 'batch_size': 2}. Best is trial 0 with value: 0.10374657834569614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — avg loss: 0.1066\n",
      "Returning final average loss across epochs: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 3/3 [00:00<00:00, 27.45it/s, loss=0.1071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 3/3 [00:00<00:00, 27.72it/s, loss=0.0999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 3/3 [00:00<00:00, 27.70it/s, loss=0.0919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 3/3 [00:00<00:00, 27.65it/s, loss=0.0800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — avg loss: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 3/3 [00:00<00:00, 27.70it/s, loss=0.0625]\n",
      "[I 2025-11-05 13:03:58,302] Trial 2 finished with value: 0.09210727711518604 and parameters: {'r': 12, 'alpha': 18.3052364475463, 'lr': 0.0006116314470293658, 'batch_size': 4}. Best is trial 2 with value: 0.09210727711518604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — avg loss: 0.0685\n",
      "Returning final average loss across epochs: 0.0921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 3/3 [00:00<00:00, 27.75it/s, loss=0.1060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 3/3 [00:00<00:00, 27.71it/s, loss=0.0976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 0.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 3/3 [00:00<00:00, 27.63it/s, loss=0.0876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 0.0915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 3/3 [00:00<00:00, 27.79it/s, loss=0.0711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — avg loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 3/3 [00:00<00:00, 27.72it/s, loss=0.0563]\n",
      "[I 2025-11-05 13:03:58,863] Trial 3 finished with value: 0.08777781104048094 and parameters: {'r': 16, 'alpha': 44.67083647483622, 'lr': 0.000375660349465526, 'batch_size': 4}. Best is trial 3 with value: 0.08777781104048094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — avg loss: 0.0604\n",
      "Returning final average loss across epochs: 0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 3/3 [00:00<00:00, 27.49it/s, loss=0.1127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 3/3 [00:00<00:00, 27.55it/s, loss=0.1119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 3/3 [00:00<00:00, 27.51it/s, loss=0.1125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 0.1123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 3/3 [00:00<00:00, 27.45it/s, loss=0.1121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — avg loss: 0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 3/3 [00:00<00:00, 27.39it/s, loss=0.1120]\n",
      "[I 2025-11-05 13:03:59,429] Trial 4 finished with value: 0.11230654517809549 and parameters: {'r': 15, 'alpha': 9.782495161117524, 'lr': 1.071356363059682e-05, 'batch_size': 4}. Best is trial 3 with value: 0.08777781104048094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — avg loss: 0.1122\n",
      "Returning final average loss across epochs: 0.1123\n",
      "Best hyperparameters: {'r': 16, 'alpha': 44.67083647483622, 'lr': 0.000375660349465526, 'batch_size': 4}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from src.fine_tuning.fine_tuning import LoraFinetuner\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    r = trial.suggest_int(\"r\", 4, 32)\n",
    "    alpha = int(trial.suggest_float(\"alpha\", 8, 64))\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [2, 4]) # TODO - Reduced batch sizes for testing\n",
    "\n",
    "    try:\n",
    "        # Create model with these LoRA params\n",
    "        finetuner = LoraFinetuner(\n",
    "            base_model=species_model,\n",
    "            batch_size=batch_size,\n",
    "            r=r,\n",
    "            alpha=alpha,\n",
    "            lr=lr\n",
    "        )\n",
    "    \n",
    "    \n",
    "        # Train on all data (no frozen embeddings)\n",
    "        final_loss = finetuner.train(\n",
    "            species_batch.tolist(),\n",
    "            sequence_batch.tolist(),\n",
    "            frozen_embeddings=None,\n",
    "            epochs=5\n",
    "        )\n",
    "        \n",
    "        if final_loss is None or np.isnan(final_loss):\n",
    "                final_loss = float(\"inf\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # print(f\"⚠️ Trial {trial.number} failed: {e}\")\n",
    "        # final_loss = float(\"inf\")\n",
    "        # raise optuna.exceptions.TrialPruned()\n",
    "        print(f\"Trial {trial.number} failed: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "        final_loss = float(\"inf\")\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T13:03:59.431301Z",
     "start_time": "2025-11-05T13:03:55.644595Z"
    }
   },
   "id": "b1caf013679b6227",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T13:03:59.434829Z",
     "start_time": "2025-11-05T13:03:59.432890Z"
    }
   },
   "id": "8157022c2bca1536",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define objective function for LoRA hyperparameter tuning (with masked embeddings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9062a970e0568e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-05 15:47:14,534] A new study created in memory with name: no-name-60dcf7f5-a119-4587-b259-d454c84e3ebf\n",
      "/tmp/ipykernel_41504/2033044651.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "Epoch 1/3: 100%|██████████| 3/3 [00:00<00:00,  6.60it/s, loss=5.7720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 5.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 3/3 [00:00<00:00, 15.33it/s, loss=5.6335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 5.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 3/3 [00:00<00:00, 15.83it/s, loss=5.5365]\n",
      "[I 2025-11-05 15:47:15,783] Trial 0 finished with value: 0.0 and parameters: {'r': 20, 'alpha': 52.26044371272665, 'lr': 0.0006513759522130387, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 5.5609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 3/3 [00:00<00:00, 15.76it/s, loss=5.8136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 5.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 3/3 [00:00<00:00, 15.84it/s, loss=5.6582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 5.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 3/3 [00:00<00:00, 15.79it/s, loss=5.6656]\n",
      "[I 2025-11-05 15:47:16,369] Trial 1 finished with value: 0.0 and parameters: {'r': 24, 'alpha': 53.419154995654615, 'lr': 0.000157752270494732, 'batch_size': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 5.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6/6 [00:00<00:00, 28.02it/s, loss=5.7900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 5.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6/6 [00:00<00:00, 28.58it/s, loss=5.8192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 5.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6/6 [00:00<00:00, 28.56it/s, loss=5.7928]\n",
      "[I 2025-11-05 15:47:17,021] Trial 2 finished with value: 0.0 and parameters: {'r': 31, 'alpha': 24.592364444011142, 'lr': 4.938932297963774e-05, 'batch_size': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 5.7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6/6 [00:00<00:00, 28.16it/s, loss=5.8272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 5.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6/6 [00:00<00:00, 28.49it/s, loss=5.8085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 5.7917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6/6 [00:00<00:00, 28.28it/s, loss=5.7659]\n",
      "[I 2025-11-05 15:47:17,672] Trial 3 finished with value: 0.0 and parameters: {'r': 8, 'alpha': 63.256457314511, 'lr': 3.132726238619787e-05, 'batch_size': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 5.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6/6 [00:00<00:00, 28.41it/s, loss=5.7040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 5.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6/6 [00:00<00:00, 28.87it/s, loss=5.8553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 5.7935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6/6 [00:00<00:00, 28.94it/s, loss=5.7904]\n",
      "[I 2025-11-05 15:47:18,315] Trial 4 finished with value: 0.0 and parameters: {'r': 26, 'alpha': 42.53729589137802, 'lr': 2.930462078712776e-05, 'batch_size': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 5.7956\n",
      "Best hyperparameters: {'r': 20, 'alpha': 52.26044371272665, 'lr': 0.0006513759522130387, 'batch_size': 4}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from src.fine_tuning.fine_tuning import LoraFinetuner, LoraFinetunerMLM\n",
    "\n",
    "def objective(trial, species_model, species_batch, sequence_batch, mode=\"mlm\"):\n",
    "    \"\"\"\n",
    "    Optuna objective for tuning LoRA hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial\n",
    "        species_model: SpeciesAwareESM2 object\n",
    "        species_batch: list of species strings\n",
    "        sequence_batch: list of sequences\n",
    "        mode: \"mlm\" for Masked LM or \"embedding\" for L2 alignment\n",
    "    \"\"\"\n",
    "    # --- Suggest hyperparameters ---\n",
    "    r = trial.suggest_int(\"r\", 4, 32)\n",
    "    alpha = int(trial.suggest_float(\"alpha\", 8, 64))\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [2, 4])\n",
    "\n",
    "    try:\n",
    "        # --- Initialize correct LoRA finetuner ---\n",
    "        if mode == \"mlm\":\n",
    "            finetuner = LoraFinetunerMLM(\n",
    "                base_model=species_model,\n",
    "                r=r, alpha=alpha, lr=lr, batch_size=batch_size\n",
    "            )\n",
    "        elif mode == \"embedding\":\n",
    "            finetuner = LoraFinetuner(\n",
    "                base_model=species_model,\n",
    "                r=r, alpha=alpha, lr=lr, batch_size=batch_size\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "        # --- Train the model ---\n",
    "        if mode == \"embedding\":\n",
    "            final_loss = finetuner.train(\n",
    "                species_batch=species_batch,\n",
    "                sequence_batch=sequence_batch,\n",
    "                frozen_embeddings=None,\n",
    "                epochs=3\n",
    "            )\n",
    "        else:  # MLM\n",
    "            finetuner.train(\n",
    "                species_batch=species_batch,\n",
    "                sequence_batch=sequence_batch,\n",
    "                epochs=3\n",
    "            )\n",
    "            # For MLM we can approximate final loss by embedding mean\n",
    "            final_loss = 0.0  # Optuna just needs a scalar; MLM returns per-step loss\n",
    "\n",
    "        # Fallback in case of NaN\n",
    "        if final_loss is None or np.isnan(final_loss):\n",
    "            final_loss = float(\"inf\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "        final_loss = float(\"inf\")\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "# --- Create and run study ---\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, species_model, species_batch.tolist(), sequence_batch.tolist(), mode=\"mlm\"),\n",
    "    n_trials=5\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T15:47:18.317402Z",
     "start_time": "2025-11-05T15:47:14.525283Z"
    }
   },
   "id": "ee208ae38cf6d0b0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "266a87eb0a60392"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
