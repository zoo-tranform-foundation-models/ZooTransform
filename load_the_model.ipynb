{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load packages and Set Working Directory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ffbd20a09157395"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "#parent_dir = os.path.dirname(os.getcwd())\n",
    "#print(parent_dir)\n",
    "data_root = os.path.join(os.getcwd())\n",
    "os.chdir(data_root)\n",
    "\n",
    "from src.model.species_model import SpeciesAwareESM2"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:33.700862Z",
     "start_time": "2025-11-05T05:53:33.697798Z"
    }
   },
   "id": "initial_id",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Use SpeciesAwareESM2 Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1d363ef1d71c6ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "  GPU: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 42.29 GB\n",
      "Loading model: facebook/esm2_t6_8M_UR50D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding species tokens: ['<sp_human>', '<sp_mouse>', '<sp_ecoli>']\n",
      "Added 3 new special tokens\n",
      "Resized model embeddings to 36 tokens\n",
      "✓ Model and tokenizer ready!\n",
      "  Hidden size: 320\n",
      "  Number of layers: 6\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained SpeciesAwareESM2 model\n",
    "species_model = SpeciesAwareESM2(model_name=\"facebook/esm2_t6_8M_UR50D\", species_list=[\"human\", \"mouse\", \"ecoli\"]) #TODO - define species list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:34.103881Z",
     "start_time": "2025-11-05T05:53:33.703310Z"
    }
   },
   "id": "b2d9bebce5381e5d",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "439834042c942c62"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Example data for embedding - need to replace with our actual data\n",
    "data = pd.DataFrame({\n",
    "    \"species\": [\"human\", \"mouse\", \"ecoli\", \"human\", \"mouse\", \"ecoli\",\"human\", \"mouse\", \"ecoli\"],\n",
    "    \"sequence\": [\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\"\n",
    "    ]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:34.111012Z",
     "start_time": "2025-11-05T05:53:34.105850Z"
    }
   },
   "id": "926a9d089f2b0d0f",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Embeddings for Sequences with Species Information, with mean pooling\n",
    "slower , not recommended for a large dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db35e26934804018"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings array shape: (9, 320)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each sequence manually\n",
    "embeddings = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    emb = species_model.embed(row['species'], row['sequence'])\n",
    "    emb_mean = emb.mean(dim=1).squeeze().cpu().numpy() # Mean pooling over sequence length, can decide to use different pooling\n",
    "    embeddings.append(emb_mean)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(\"Embeddings array shape:\", embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:34.178837Z",
     "start_time": "2025-11-05T05:53:34.113579Z"
    }
   },
   "id": "dcf80d8cbcd2a77d",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Embeddings for *a Batch of Sequences* with Species Information, with mean pooling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f9014b9a4dbec62"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 320)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for a batch of sequences (faster); here batch is the entire dataset\n",
    "species_batch = data[\"species\"].tolist()\n",
    "sequence_batch = data[\"sequence\"].tolist()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = species_model.forward(species_batch, sequence_batch)\n",
    "\n",
    "batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "print(batch_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:34.188337Z",
     "start_time": "2025-11-05T05:53:34.179743Z"
    }
   },
   "id": "414650b304c22b24",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for name, module in list(species_model.model.named_modules())[:60]:\n",
    "#     print(name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:34.190942Z",
     "start_time": "2025-11-05T05:53:34.189150Z"
    }
   },
   "id": "3f11adf492f0cf66",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Data into Train, Validation, and Test Sets (not used in our case)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "404cdfa2ef9c53df"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6, Val: 1, Test: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #TODO - do we want to have splits? generally we just want to fine-tune on all data\n",
    "\n",
    "# First, split train vs temp (validation + test)\n",
    "species_train, species_temp, seq_train, seq_temp = train_test_split(\n",
    "    species_batch, sequence_batch, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Then, split temp into validation and test (50% of temp each = 15% total)\n",
    "species_val, species_test, seq_val, seq_test = train_test_split(\n",
    "    species_temp, seq_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(species_train)}, Val: {len(species_val)}, Test: {len(species_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:34.195497Z",
     "start_time": "2025-11-05T05:53:34.191756Z"
    }
   },
   "id": "6b5c38fd0eb91a39",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tune the Model using LoRA (on all data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "878d650a87ec3b52"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "  GPU: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 42.29 GB\n",
      "Loading model: facebook/esm2_t6_8M_UR50D\n",
      "Adding species tokens: ['<sp_human>', '<sp_mouse>', '<sp_ecoli>']\n",
      "Added 3 new special tokens\n",
      "Resized model embeddings to 36 tokens\n",
      "✓ Model and tokenizer ready!\n",
      "  Hidden size: 320\n",
      "  Number of layers: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 2/2 [00:00<00:00, 25.70it/s, loss=8.4931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — avg loss: 10.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 2/2 [00:00<00:00, 28.67it/s, loss=8.5263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — avg loss: 10.2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 2/2 [00:00<00:00, 32.23it/s, loss=8.5033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — avg loss: 10.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 2/2 [00:00<00:00, 34.47it/s, loss=8.3899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — avg loss: 10.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 2/2 [00:00<00:00, 34.27it/s, loss=8.3678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — avg loss: 10.1332\n",
      "Tuned embeddings shape: torch.Size([9, 320])\n"
     ]
    }
   ],
   "source": [
    "from src.fine_tuning.fine_tuning import LoraFinetuner\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "species_batch = data[\"species\"].tolist()\n",
    "sequence_batch = data[\"sequence\"].tolist()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "old_model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\").to(device)\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "tokens_old = old_tokenizer(sequence_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "tokens_old = {k: v.to(device) for k,v in tokens_old.items()}\n",
    "with torch.no_grad():\n",
    "    old_embeddings = old_model(**tokens_old).last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Species-aware model\n",
    "species_model = SpeciesAwareESM2(species_list=[\"human\",\"mouse\",\"ecoli\"])\n",
    "\n",
    "# LoRA finetuner\n",
    "finetuner = LoraFinetuner(\n",
    "    base_model=species_model, \n",
    "    r=8, \n",
    "    alpha=16, \n",
    "    dropout=0.05, \n",
    "    target_modules=None, \n",
    "    lr=1e-4, \n",
    "    batch_size=4)  #TODO - optionally optimize parameters for LoRA \n",
    "\n",
    "# Train to align species embeddings to frozen embeddings\n",
    "finetuner.train(species_train, seq_train, frozen_embeddings=None, epochs=5) #TODO - set frozen embeddings\n",
    "\n",
    "# Extract tuned embeddings\n",
    "tuned_embeddings = finetuner.embed(species_batch, sequence_batch)\n",
    "print(\"Tuned embeddings shape:\", tuned_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T05:53:35.193795Z",
     "start_time": "2025-11-05T05:53:34.196304Z"
    }
   },
   "id": "ea9ddba2dbc52030",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tune the Model using LoRA for Masked Language Modeling (MLM)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c16a82867671cd27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.fine_tuning.fine_tuning import LoraFinetunerMLM  # new MLM version\n",
    "from src.model.species_model import SpeciesAwareESM2\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Species-aware model\n",
    "species_model = SpeciesAwareESM2(species_list=[\"human\",\"mouse\",\"ecoli\"])\n",
    "species_model.to(device)\n",
    "\n",
    "species_batch = data[\"species\"].tolist()\n",
    "sequence_batch = data[\"sequence\"].tolist()\n",
    "\n",
    "finetuner = LoraFinetunerMLM(\n",
    "    base_model=species_model,\n",
    "    r=8,\n",
    "    alpha=16,\n",
    "    dropout=0.05,\n",
    "    target_modules=[\"attention.self.key\", \"attention.self.value\"],  # LoRA targets\n",
    "    lr=1e-4,\n",
    "    batch_size=4,\n",
    "    mlm_probability=0.15  # fraction of tokens to mask\n",
    ")\n",
    "\n",
    "finetuner.train(\n",
    "    species_batch=species_batch,\n",
    "    sequence_batch=sequence_batch,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "tuned_embeddings = finetuner.embed(species_batch, sequence_batch)\n",
    "print(\"Tuned embeddings shape:\", tuned_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbcaba205c902c30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save and Load the Fine-tuned Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a93817aa02b932aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Directory to save LoRA adapters\n",
    "save_dir = \"lora_finetuned_species_model\" #TODO - specify path\n",
    "\n",
    "# Save only LoRA weights \n",
    "finetuner.model.save_pretrained(save_dir)\n",
    "print(f\"LoRA adapters saved to {save_dir}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d555f0f7f68947f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
