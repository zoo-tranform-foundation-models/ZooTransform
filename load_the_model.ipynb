{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load packages and Set Working Directory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ffbd20a09157395"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "data_root = os.path.join(parent_dir, \"ZooTransform\")\n",
    "os.chdir(data_root)\n",
    "\n",
    "from src.model.species_model import SpeciesAwareESM2"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:15.466834Z",
     "start_time": "2025-11-05T01:54:15.461876Z"
    }
   },
   "id": "initial_id",
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Use SpeciesAwareESM2 Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1d363ef1d71c6ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using device: cuda\n",
      "  GPU: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 42.29 GB\n",
      "üì• Loading model: facebook/esm2_t6_8M_UR50D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/esm2_t6_8M_UR50D/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f199ae6f4a0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: b4a5f838-2e5a-4bbb-820f-b54bd23bb8ad)')' thrown while requesting HEAD https://huggingface.co/facebook/esm2_t6_8M_UR50D/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/resolve-cache/models/facebook/esm2_t6_8M_UR50D/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f193eb7e7b0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: d79f7f61-92d1-4dcb-9ce9-c8163792db86)')' thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/facebook/esm2_t6_8M_UR50D/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding species tokens: ['<sp_human>', '<sp_mouse>', '<sp_ecoli>']\n",
      "Added 3 new special tokens\n",
      "Resized model embeddings to 36 tokens\n",
      "‚úì Model and tokenizer ready!\n",
      "  Hidden size: 320\n",
      "  Number of layers: 6\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained SpeciesAwareESM2 model\n",
    "model = SpeciesAwareESM2(model_name=\"facebook/esm2_t6_8M_UR50D\", species_list=[\"human\", \"mouse\", \"ecoli\"]) #TODO - define species list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:55.035855Z",
     "start_time": "2025-11-05T01:54:15.469506Z"
    }
   },
   "id": "b2d9bebce5381e5d",
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "439834042c942c62"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Example data for embedding - need to replace with our actual data\n",
    "data = pd.DataFrame({\n",
    "    \"species\": [\"human\", \"mouse\", \"ecoli\"],\n",
    "    \"sequence\": [\n",
    "        \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "        \"MKVSAIAKQRQISFVKSHFSRQLRERLGLIEVQ\",\n",
    "        \"MKTVYIAKQRQISFVKSHFSRQLEERLGLIEVQ\"\n",
    "    ]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:55.042358Z",
     "start_time": "2025-11-05T01:54:55.037690Z"
    }
   },
   "id": "926a9d089f2b0d0f",
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Embeddings for Sequences with Species Information, with mean pooling\n",
    "slower , not recommended for a large dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db35e26934804018"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings array shape: (3, 320)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each sequence manually\n",
    "embeddings = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    emb = model.embed(row['species'], row['sequence'])\n",
    "    emb_mean = emb.mean(dim=1).squeeze().cpu().numpy() # Mean pooling over sequence length, can decide to use different pooling\n",
    "    embeddings.append(emb_mean)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(\"Embeddings array shape:\", embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:55.065401Z",
     "start_time": "2025-11-05T01:54:55.045062Z"
    }
   },
   "id": "dcf80d8cbcd2a77d",
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Embeddings for *a Batch of Sequences* with Species Information, with mean pooling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f9014b9a4dbec62"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 320)\n"
     ]
    }
   ],
   "source": [
    "species_batch = data['species'].tolist()\n",
    "sequence_batch = data['sequence'].tolist()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.forward(species_batch, sequence_batch)\n",
    "\n",
    "batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "print(batch_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:55.074811Z",
     "start_time": "2025-11-05T01:54:55.066211Z"
    }
   },
   "id": "414650b304c22b24",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embeddings\n",
      "embeddings.word_embeddings\n",
      "embeddings.dropout\n",
      "embeddings.position_embeddings\n",
      "encoder\n",
      "encoder.layer\n",
      "encoder.layer.0\n",
      "encoder.layer.0.attention\n",
      "encoder.layer.0.attention.self\n",
      "encoder.layer.0.attention.self.query\n",
      "encoder.layer.0.attention.self.key\n",
      "encoder.layer.0.attention.self.value\n",
      "encoder.layer.0.attention.self.dropout\n",
      "encoder.layer.0.attention.self.rotary_embeddings\n",
      "encoder.layer.0.attention.output\n",
      "encoder.layer.0.attention.output.dense\n",
      "encoder.layer.0.attention.output.dropout\n",
      "encoder.layer.0.attention.LayerNorm\n",
      "encoder.layer.0.intermediate\n",
      "encoder.layer.0.intermediate.dense\n",
      "encoder.layer.0.output\n",
      "encoder.layer.0.output.dense\n",
      "encoder.layer.0.output.dropout\n",
      "encoder.layer.0.LayerNorm\n",
      "encoder.layer.1\n",
      "encoder.layer.1.attention\n",
      "encoder.layer.1.attention.self\n",
      "encoder.layer.1.attention.self.query\n",
      "encoder.layer.1.attention.self.key\n",
      "encoder.layer.1.attention.self.value\n",
      "encoder.layer.1.attention.self.dropout\n",
      "encoder.layer.1.attention.self.rotary_embeddings\n",
      "encoder.layer.1.attention.output\n",
      "encoder.layer.1.attention.output.dense\n",
      "encoder.layer.1.attention.output.dropout\n",
      "encoder.layer.1.attention.LayerNorm\n",
      "encoder.layer.1.intermediate\n",
      "encoder.layer.1.intermediate.dense\n",
      "encoder.layer.1.output\n",
      "encoder.layer.1.output.dense\n",
      "encoder.layer.1.output.dropout\n",
      "encoder.layer.1.LayerNorm\n",
      "encoder.layer.2\n",
      "encoder.layer.2.attention\n",
      "encoder.layer.2.attention.self\n",
      "encoder.layer.2.attention.self.query\n",
      "encoder.layer.2.attention.self.key\n",
      "encoder.layer.2.attention.self.value\n",
      "encoder.layer.2.attention.self.dropout\n",
      "encoder.layer.2.attention.self.rotary_embeddings\n",
      "encoder.layer.2.attention.output\n",
      "encoder.layer.2.attention.output.dense\n",
      "encoder.layer.2.attention.output.dropout\n",
      "encoder.layer.2.attention.LayerNorm\n",
      "encoder.layer.2.intermediate\n",
      "encoder.layer.2.intermediate.dense\n",
      "encoder.layer.2.output\n",
      "encoder.layer.2.output.dense\n",
      "encoder.layer.2.output.dropout\n"
     ]
    }
   ],
   "source": [
    "for name, module in list(model.model.named_modules())[:60]:\n",
    "    print(name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:55.078273Z",
     "start_time": "2025-11-05T01:54:55.075579Z"
    }
   },
   "id": "3f11adf492f0cf66",
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tune the Model using LoRA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "878d650a87ec3b52"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using device: cuda\n",
      "  GPU: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 42.29 GB\n",
      "üì• Loading model: facebook/esm2_t6_8M_UR50D\n",
      "Adding species tokens: ['<sp_human>', '<sp_mouse>', '<sp_ecoli>']\n",
      "Added 3 new special tokens\n",
      "Resized model embeddings to 36 tokens\n",
      "‚úì Model and tokenizer ready!\n",
      "  Hidden size: 320\n",
      "  Number of layers: 6\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[126]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# # ---- Create and train LoRA finetuner ----\u001B[39;00m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# finetuner = LoraESMFinetuner(\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m#     base_model=model,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# finetuner.train(species_batch, sequence_batch, epochs=10)\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m     old_outputs = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m                             \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m                             \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m teacher_embeddings = old_outputs.last_hidden_state.cpu().numpy()\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# 3Ô∏è‚É£ Initialize LoRA finetuner\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esm.py:862\u001B[39m, in \u001B[36mEsmModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    860\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mYou cannot specify both input_ids and inputs_embeds at the same time\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    861\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m862\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwarn_if_padding_and_no_attention_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    863\u001B[39m     input_shape = input_ids.size()\n\u001B[32m    864\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4755\u001B[39m, in \u001B[36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001B[39m\u001B[34m(self, input_ids, attention_mask)\u001B[39m\n\u001B[32m   4752\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m   4754\u001B[39m \u001B[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4755\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.pad_token_id \u001B[38;5;129;01min\u001B[39;00m \u001B[43minput_ids\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m:\n\u001B[32m   4756\u001B[39m     warn_string = (\n\u001B[32m   4757\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4758\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mhttps://huggingface.co/docs/transformers/troubleshooting\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4759\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m#incorrect-output-when-padding-tokens-arent-masked.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4760\u001B[39m     )\n\u001B[32m   4762\u001B[39m     \u001B[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001B[39;00m\n\u001B[32m   4763\u001B[39m     \u001B[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:276\u001B[39m, in \u001B[36mBatchEncoding.__getitem__\u001B[39m\u001B[34m(self, item)\u001B[39m\n\u001B[32m    274\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {key: \u001B[38;5;28mself\u001B[39m.data[key][item] \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.data.keys()}\n\u001B[32m    275\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[32m    277\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mInvalid key. Only three types of key are available: \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    278\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m(1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    279\u001B[39m     )\n",
      "\u001B[31mKeyError\u001B[39m: 'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.'"
     ]
    }
   ],
   "source": [
    "from src.fine_tuning.fine_tuning import LoraFinetuner\n",
    "\n",
    "# ---- Instantiate base model ----\n",
    "species_list = [\"human\", \"mouse\", \"ecoli\"] #TODO - define species list\n",
    "model = SpeciesAwareESM2(species_list=species_list)\n",
    "\n",
    "# ---- Prepare your data ----\n",
    "species_batch = data[\"species\"].tolist()\n",
    "sequence_batch = data[\"sequence\"].tolist()\n",
    "\n",
    "# # ---- Create and train LoRA finetuner ----\n",
    "# finetuner = LoraESMFinetuner(\n",
    "#     base_model=model,\n",
    "#     r=8,\n",
    "#     alpha=16,\n",
    "#     dropout=0.05,\n",
    "#     lr=1e-4,\n",
    "#     batch_size=4,\n",
    "#     mlm_probability=0.15,\n",
    "# )\n",
    "# \n",
    "# finetuner.train(species_batch, sequence_batch, epochs=10)\n",
    "with torch.no_grad():\n",
    "    old_outputs = model.model(\n",
    "        model.tokenizer(sequence_batch, return_tensors=\"pt\",\n",
    "                             padding=True, truncation=True,\n",
    "                             max_length=model.max_length).to(model.device)\n",
    "    )\n",
    "teacher_embeddings = old_outputs.last_hidden_state.cpu().numpy()\n",
    "\n",
    "# 3Ô∏è‚É£ Initialize LoRA finetuner\n",
    "finetuner = LoraFinetuner(model, r=8, alpha=16, dropout=0.05, lr=1e-4, batch_size=4)\n",
    "\n",
    "# 4Ô∏è‚É£ Train LoRA to add species-awareness\n",
    "finetuner.train(species_batch, sequence_batch, teacher_embeddings, epochs=5)\n",
    "\n",
    "# 5Ô∏è‚É£ Get species-aware embeddings\n",
    "species_aware_embeddings = finetuner.embed(species_batch, sequence_batch)\n",
    "print(species_aware_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T01:54:55.671043Z",
     "start_time": "2025-11-05T01:54:55.079080Z"
    }
   },
   "id": "f46046353053052f",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tuned_embeddings = finetuner.embed(species_batch, sequence_batch)\n",
    "\n",
    "print(\"Tuned embedding shape:\", tuned_embeddings.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5ac590c191d6401"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "finetuner.model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "310fa12d86988b6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LoraFinetuner' from 'src.fine_tuning.fine_tuning' (/workspace/ZooTransform/src/fine_tuning/fine_tuning.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[127]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfine_tuning\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfine_tuning\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LoraFinetuner\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoModel, AutoTokenizer\n\u001B[32m      4\u001B[39m device = \u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'LoraFinetuner' from 'src.fine_tuning.fine_tuning' (/workspace/ZooTransform/src/fine_tuning/fine_tuning.py)"
     ]
    }
   ],
   "source": [
    "from src.fine_tuning.fine_tuning import LoraFinetuner\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "old_model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\").to(device)\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "tokens_old = old_tokenizer(sequence_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "tokens_old = {k: v.to(device) for k,v in tokens_old.items()}\n",
    "with torch.no_grad():\n",
    "    old_embeddings = old_model(**tokens_old).last_hidden_state.mean(dim=1)\n",
    "\n",
    "# 2Ô∏è‚É£ Species-aware model\n",
    "species_model = SpeciesAwareESM2(species_list=[\"human\",\"mouse\",\"ecoli\"])\n",
    "\n",
    "# 3Ô∏è‚É£ LoRA finetuner\n",
    "finetuner = LoraFinetuner(base_model=species_model, batch_size=4)\n",
    "\n",
    "# 4Ô∏è‚É£ Train to align species embeddings to frozen embeddings\n",
    "finetuner.train(species_batch, sequence_batch, frozen_embeddings=old_embeddings, epochs=5)\n",
    "\n",
    "# 5Ô∏è‚É£ Extract tuned embeddings\n",
    "tuned_embeddings = finetuner.embed(species_batch, sequence_batch)\n",
    "print(\"Tuned embeddings shape:\", tuned_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-05T02:14:57.803355Z",
     "start_time": "2025-11-05T02:14:57.766833Z"
    }
   },
   "id": "ea9ddba2dbc52030",
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d4c141c323c58ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
